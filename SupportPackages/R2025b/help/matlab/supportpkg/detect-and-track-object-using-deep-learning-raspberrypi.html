<!DOCTYPE HTML>
<html xmlns="http://www.w3.org/1999/xhtml" itemscope="" itemtype="http://www.mathworks.com/help/schema/MathWorksDocPage">
<head>
<meta xmlns="http://www.w3.org/1999/xhtml" charset="utf-8">
<meta xmlns="http://www.w3.org/1999/xhtml" name="viewport" content="width=device-width, initial-scale=1.0">
<meta xmlns="http://www.w3.org/1999/xhtml" http-equiv="X-UA-Compatible" content="IE=edge">
<title>Detect and Track Object Using Deep Learning on Raspberry Pi</title>
<script xmlns="http://www.w3.org/1999/xhtml" type="application/ld+json">
      {
      "@context": "http://schema.org",
      "@type": "BreadcrumbList",
      "itemListElement":
      [{
          "@type": "ListItem",
          "position": 1,

          "item": {
          "@id": "../index.html",
          "name": "MATLAB"
}

          } 
        ,
        {
          "@type": "ListItem",
          "position": 2,

          "item": {
          "@id": "../data-import-and-analysis.html",
          "name": "Data Import and Analysis"
}

          }
        ,
        {
          "@type": "ListItem",
          "position": 3,

          "item": {
          "@id": "../data-import-and-export.html",
          "name": "Data Import and Export"
}

          }
        ,
        {
          "@type": "ListItem",
          "position": 4,

          "item": {
          "@id": "../hardware-network-comm.html",
          "name": "Hardware and Network Communication"
}

          }
        ,
        {
          "@type": "ListItem",
          "position": 5,

          "item": {
          "@id": "../hardware-boards-and-kits.html",
          "name": "Hardware Boards and Kits"
}

          }
        ,
        {
          "@type": "ListItem",
          "position": 6,

          "item": {
          "@id": "../raspberrypiio.html",
          "name": "Raspberry Pi Hardware"
}

          }
        ,
        {
          "@type": "ListItem",
          "position": 7,

          "item": {
          "@id": "../raspberrypiio-camera-board.html",
          "name": "Camera Board"
}

          }]
      }</script><script xmlns="http://www.w3.org/1999/xhtml" type="application/ld+json">
      {
      "@context": "http://schema.org",
      "@type": "BreadcrumbList",
      "itemListElement":
      [{
          "@type": "ListItem",
          "position": 1,

          "item": {
          "@id": "../index.html",
          "name": "MATLAB"
}

          } 
        ,
        {
          "@type": "ListItem",
          "position": 2,

          "item": {
          "@id": "../data-import-and-analysis.html",
          "name": "Data Import and Analysis"
}

          }
        ,
        {
          "@type": "ListItem",
          "position": 3,

          "item": {
          "@id": "../data-import-and-export.html",
          "name": "Data Import and Export"
}

          }
        ,
        {
          "@type": "ListItem",
          "position": 4,

          "item": {
          "@id": "../hardware-network-comm.html",
          "name": "Hardware and Network Communication"
}

          }
        ,
        {
          "@type": "ListItem",
          "position": 5,

          "item": {
          "@id": "../hardware-boards-and-kits.html",
          "name": "Hardware Boards and Kits"
}

          }
        ,
        {
          "@type": "ListItem",
          "position": 6,

          "item": {
          "@id": "../raspberrypiio.html",
          "name": "Raspberry Pi Hardware"
}

          }
        ,
        {
          "@type": "ListItem",
          "position": 7,

          "item": {
          "@id": "../raspberrypiio-webcam.html",
          "name": "Web Camera"
}

          }]
      }</script><script xmlns="http://www.w3.org/1999/xhtml" type="application/ld+json">
        {
        "@context": "http://schema.org",
        "@type": "ItemList",
          "name": "VisibleBreadcrumbs",

        "itemListElement":
        [
        "raspberrypiio-camera-board",
        "raspberrypiio-webcam"
        ],
        "itemListOrder": "http://schema.org/ItemListOrderAscending"
        }
        </script><script xmlns="http://www.w3.org/1999/xhtml" type="application/ld+json">
        {
        "@context": "http://schema.org",
        "@type": "DigitalDocument",
          "headline": "Detect and Track Object Using Deep Learning on Raspberry Pi",
          "description": "Use the MATLAB&#174; Support Package for Raspberry Pi&#174; Hardware to deploy a deep learning algorithm that detects and tracks an object in Connected IO and PIL modes. This algorithm uses the ResNet-18-based YOLOv2 neural network to identify the object captured by the camera mounted on a servo motor and connected to the Raspberry Pi hardware. You can experiment with different objects in your surroundings to see how accurately the network detects images on the Raspberry Pi hardware.",
          "thumbnailURL": "../../examples/raspberrypiio/win64/detection_PIL_mode.PNG",
          "genre": "Script",
          "isBasedOn": {
          "@type": "Product",
          "name": "MATLAB"

        },
          "identifier": "raspberrypiio.DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample",
          "name": "DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample",
          "url": "detect-and-track-object-using-deep-learning-raspberrypi.html"

        }</script><script xmlns="http://www.w3.org/1999/xhtml" type="application/ld+json">
        {
        "@context": "http://schema.org",
        "@type": "PropertyValue",
          "name": "open_command",
          "value": "matlab:openExample('raspberrypiio/DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample')"

        }</script><script xmlns="http://www.w3.org/1999/xhtml" type="application/ld+json">
        {
        "@context": "http://schema.org",
        "@type": "ItemList",
          "name": "ExampleSourceFiles",

        "itemListElement":
        [
        "DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample.m",
        "raspi_object_tracking.m",
        "raspi_yolov2_detect.m",
        "raspiObjectTracker.m",
        "video_Labeler_app.PNG",
        "tracking_PIL_mode.PNG",
        "tracking_PIL_message.PNG",
        "tracking_connectedIO_mode.PNG",
        "tracking_connectedIO_message.PNG",
        "objectTrackingSetup.png",
        "figure_window.PNG",
        "detection_PIL_mode.PNG",
        "detection_PIL_message.PNG",
        "detection_connectedIO_mode.PNG",
        "deploy_raspberrypi_hardware.PNG",
        "createObjectDetector.PNG",
        "code_execution_profiling_report.PNG"
        ],
        "itemListOrder": "http://schema.org/ItemListOrderAscending"
        }
        </script><link xmlns="http://www.w3.org/1999/xhtml" href="../../includes/product/css/bootstrap.min.css" rel="stylesheet" type="text/css">


  <meta xmlns="http://www.w3.org/1999/xhtml" http-equiv="Content-Script-Type" content="text/javascript">
<meta xmlns="http://www.w3.org/1999/xhtml" name="toctype" itemprop="pagetype" content="fe">
<meta xmlns="http://www.w3.org/1999/xhtml" name="infotype" itemprop="infotype" content="ex">

<meta xmlns="http://www.w3.org/1999/xhtml" name="description" itemprop="description" content="This example shows how to use the MATLAB&#174; Support Package for Raspberry Pi&#174; Hardware to deploy a deep learning algorithm that detects and tracks an object in Connected IO and PIL modes."><meta xmlns="http://www.w3.org/1999/xhtml" content="../../examples/raspberrypiio/win64/detection_PIL_mode.PNG" itemprop="thumbnailUrl">
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/product/scripts/jquery/jquery-3.6.0.min.js"></script><script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/product/scripts/jquery/jquery-migrate.min.js"></script>
<link xmlns="http://www.w3.org/1999/xhtml" href="../../includes/product/css/site6.css" rel="stylesheet" type="text/css">
<link xmlns="http://www.w3.org/1999/xhtml" href="../../includes/product/css/site6_lg.css" rel="stylesheet" media="screen and (min-width: 1200px)">
<link xmlns="http://www.w3.org/1999/xhtml" href="../../includes/product/css/site6_md.css" rel="stylesheet" media="screen and (min-width: 992px) and (max-width: 1199px)">
<link xmlns="http://www.w3.org/1999/xhtml" href="../../includes/product/css/site6_sm+xs.css" rel="stylesheet" media="screen and (max-width: 991px)">
<link xmlns="http://www.w3.org/1999/xhtml" href="../../includes/product/css/site6_sm.css" rel="stylesheet" media="screen and (min-width: 768px) and (max-width: 991px)">
<link xmlns="http://www.w3.org/1999/xhtml" href="../../includes/product/css/site6_xs.css" rel="stylesheet" media="screen and (max-width: 767px)">
<link xmlns="http://www.w3.org/1999/xhtml" href="../../includes/product/css/site6_offcanvas_v2.css" rel="stylesheet" type="text/css">
<link xmlns="http://www.w3.org/1999/xhtml" href="../../includes/shared/highlight/styles/mwdochighlight.min.css" rel="stylesheet" type="text/css">

<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/shared/scripts/l10n.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/shared/scripts/docscripts.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/shared/scripts/f1help.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/product/scripts/docscripts.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/shared/scripts/mw.imageanimation.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/shared/scripts/jquery.highlight.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/product/scripts/underscore-min.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/product/scripts/use_platform_screenshots.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/product/scripts/suggest.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/product/scripts/overload.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/shared/scripts/helpservices.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/product/scripts/productfilter.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/shared/scripts/matlab_dialog_shared.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/shared/highlight/highlight.min.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/shared/scripts/localstorage.js"></script><script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/shared/scripts/product_group.js"></script><script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/shared/scripts/saxonjs/SaxonJS2.rt.js"></script><script xmlns="http://www.w3.org/1999/xhtml">
            window.history.replaceState(window.location.href, null, ""); // Initialize
            window.onload = function() {    
            mystylesheetLocation = "../../includes/shared/scripts/product_group-sef.json";
            mysourceLocation = "../../docset/docset.xml";
            product_help_location = "matlab";
            pagetype = "section";
            doccentertype = "product";
            langcode = "";
            getProductFilteredList(mystylesheetLocation, mysourceLocation, product_help_location, pagetype, doccentertype, langcode);  
            }
          </script>




<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/product/scripts/jquery/jquery.mobile.custom.min.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/product/scripts/bootstrap.bundle.min.js"></script>
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/product/scripts/global.js"></script>
<link xmlns="http://www.w3.org/1999/xhtml" href="../../includes/product/css/doc_center_base.css" rel="stylesheet" type="text/css">
<link xmlns="http://www.w3.org/1999/xhtml" href="../../includes/product/css/doc_center_installed.css" rel="stylesheet" type="text/css">
<link xmlns="http://www.w3.org/1999/xhtml" href="../../includes/product/css/doc_center_print.css" rel="stylesheet" type="text/css" media="print">
<script xmlns="http://www.w3.org/1999/xhtml" src="../../includes/shared/equationrenderer/release/MathRenderer.js"></script>
</head>
<body id="responsive_offcanvas">
<div xmlns="http://www.w3.org/1999/xhtml" id="doc_header_spacer" class="header"></div>
<div xmlns="http://www.w3.org/1999/xhtml" class="section_header level_3"><div class="container-fluid"><div class="row" id="mobile_search_row"><div class="col-sm-6 col-md-7 has_horizontal_local_nav" id="section_header_title"><div class="section_header_content"><div class="section_header_title"><h1><a href="../../documentation-center.html">Help Center</a></h1></div></div></div><div class="col-12 col-sm-6 col-md-5" id="mobile_search"><div class="search_nested_content_container"><form id="docsearch_form" name="docsearch_form" method="get" data-release="R2025b" data-language="en" action="../../templates/searchresults.html"><div class="input-group tokenized_search_field"><label class="visually-hidden form-label">Search Help</label><input type="text" class="form-control conjoined_search" autocomplete="off" name="qdoc" placeholder="Search Help" id="docsearch"> <div><button type="submit" name="submitsearch" id="submitsearch" class="btn icon-search btn_search_adjacent btn_search icon_16" tabindex="-1"></button></div></div></form></div><button class="btn icon-remove btn_search float-end icon_32 d-sm-none" data-bs-toggle="collapse" href="#mobile_search" aria-expanded="false" aria-controls="mobile_search"></button></div><div class="d-sm-none" id="search_actuator"><button class="btn icon-search btn_search float-end icon_16" data-bs-toggle="collapse" href="#mobile_search" aria-expanded="false" aria-controls="mobile_search"></button></div></div></div></div><div class="row-offcanvas row-offcanvas-left">
<div xmlns="http://www.w3.org/1999/xhtml" class="sidebar-offcanvas" id="sidebar">
<nav class="offcanvas_nav" role="navigation">
<div class="offcanvas_actuator" data-bs-toggle="offcanvas" data-bs-target="#sidebar" id="nav_toggle"><button type="button" class="btn"><span class="visually-hidden">Off-Canvas Navigation Menu Toggle
                  Off-Canvas Navigation Menu Toggle</span><span class="icon-menu"></span></button><span class="offcanvas_actuator_label" id="translation_icon-menu" tabindex="-1" aria-hidden="true"></span></div><div class="nav_list_wrapper" id="nav_list_wrapper"><nav class="offcanvas_nav" role="navigation"><ul class="nav_breadcrumb" id="ul_left_nav_ancestors"><li itemscope="" itemtype="http://www.data-vocabulary.org/Breadcrumb" itemprop="breadcrumb"><a href="../../documentation-center.html?s_tid=CRUX_lftnav" itemprop="url"><span itemprop="title">Documentation Home</span></a></li></ul>
<ul class="nav_disambiguation"><li><a href="../index.html?s_tid=CRUX_lftnav" id="index">MATLAB</a>
</li>
<li itemscope="" itemtype="http://www.data-vocabulary.org/Breadcrumb" itemprop="breadcrumb"><a href="../data-import-and-analysis.html?s_tid=CRUX_lftnav" itemprop="url"><span itemprop="title">Data Import and Analysis</span></a></li><li itemscope="" itemtype="http://www.data-vocabulary.org/Breadcrumb" itemprop="breadcrumb"><a href="../data-import-and-export.html?s_tid=CRUX_lftnav" itemprop="url"><span itemprop="title">Data Import and Export</span></a></li><li itemscope="" itemtype="http://www.data-vocabulary.org/Breadcrumb" itemprop="breadcrumb"><a href="../hardware-network-comm.html?s_tid=CRUX_lftnav" itemprop="url"><span itemprop="title">Hardware and Network Communication</span></a></li><li itemscope="" itemtype="http://www.data-vocabulary.org/Breadcrumb" itemprop="breadcrumb"><a href="../hardware-boards-and-kits.html?s_tid=CRUX_lftnav" itemprop="url"><span itemprop="title">Hardware Boards and Kits</span></a></li><li itemscope="" itemtype="http://www.data-vocabulary.org/Breadcrumb" itemprop="breadcrumb"><a href="../raspberrypiio.html?s_tid=CRUX_lftnav" itemprop="url"><span itemprop="title">Raspberry Pi Hardware</span></a></li><li itemscope="" itemtype="http://www.data-vocabulary.org/Breadcrumb" itemprop="breadcrumb"><a href="../raspberrypiio-camera-board.html?s_tid=CRUX_lftnav" itemprop="url" id="mw_940c9ffb-0b25-422a-a3e3-e0141819ce71"><span itemprop="title">Camera Board</span></a></li></ul><ul class="nav_disambiguation"><li><a href="../index.html?s_tid=CRUX_lftnav" id="index">MATLAB</a>
</li>
<li><a href="../data-import-and-analysis.html?s_tid=CRUX_lftnav">Data Import and Analysis</a></li><li><a href="../data-import-and-export.html?s_tid=CRUX_lftnav">Data Import and Export</a></li><li><a href="../hardware-network-comm.html?s_tid=CRUX_lftnav">Hardware and Network Communication</a></li><li><a href="../hardware-boards-and-kits.html?s_tid=CRUX_lftnav">Hardware Boards and Kits</a></li><li><a href="../raspberrypiio.html?s_tid=CRUX_lftnav">Raspberry Pi Hardware</a></li><li><a href="../raspberrypiio-webcam.html?s_tid=CRUX_lftnav" id="mw_a4e1bff6-4aeb-4e24-ac27-0881204d8716">Web Camera</a></li></ul><div class="search_refine_v4"><div id="facets_area"><ul class="nav_scrollspy nav list-unstyled" id="pnav">
<li class="nav_scrollspy_function nav-item"><a href="#responsive_offcanvas">Detect and Track Object Using Deep Learning on Raspberry Pi</a></li>
<li class="nav_scrollspy_title nav-item" id="SSPY810-section">On this page</li>
<!--ADD_REFENTRY_TITLE_HERE 11--><li class="nav-item"><a href="#d126e121811" class="nav-link intrnllnk">Prerequisites</a></li><li class="nav-item"><a href="#d126e121820" class="nav-link intrnllnk">Required Hardware</a></li><li class="nav-item"><a href="#d126e121842" class="nav-link intrnllnk">Hardware Setup</a></li><li class="nav-item"><a href="#d126e121853" class="nav-link intrnllnk">Create Tracker Object</a></li><li class="nav-item"><a href="#d126e122041" class="nav-link intrnllnk">Detect Object</a></li><li class="nav-item"><a href="#d126e122058" class="nav-link intrnllnk">Train YOLOv2 Object Detector</a></li><li class="nav-item"><a href="#d126e122098" class="nav-link intrnllnk">Verify Object Detection in Connected IO Mode</a></li><li class="nav-item"><a href="#d126e122128" class="nav-link intrnllnk">Verify Object Detection in PIL Mode</a></li><li class="nav-item"><a href="#d126e122177" class="nav-link intrnllnk">Configure Servo Motor Parameters</a></li><li class="nav-item"><a href="#d126e122223" class="nav-link intrnllnk">Track Object in Connected IO Mode</a></li><li class="nav-item"><a href="#d126e122251" class="nav-link intrnllnk">Track Object in PIL Mode</a></li><li class="nav-item"><a href="#d126e122280" class="nav-link intrnllnk">Deploy on Raspberry Pi Target Board</a></li><li class="nav-item"><a href="#d126e122353" class="nav-link intrnllnk">Other Things to Try</a></li><li class="nav-item"><a href="#d126e122374" class="nav-link intrnllnk">See Also</a></li></ul></div></div>
</nav></div></nav>
<script src="../../includes/product/scripts/offcanvas_v2.js"></script></div><!--END.CLASS sidebar-offcanvas-->
<div class="offcanvas_content_container">
<div xmlns="http://www.w3.org/1999/xhtml" class="sticky_header_container"><div class="horizontal_nav"><div class="horizontal_nav_container"><div class="offcanvas_horizontal_nav"><div class="container-fluid"><div class="row"><div class="col-sm-12 d-none d-sm-block"><nav class="navbar navbar-default" role="navigation" id="subnav"><div><ul class="nav navbar-nav crux_browse"><li id="crux_nav_documentation" class="crux_resource active">Documentation</li><li id="crux_nav_example" class="crux_resource"><a href="../examples.html?category=raspberrypiio-camera-board&amp;s_tid=CRUX_topnav">Examples</a></li><li id="crux_nav_function" class="crux_resource"><a href="../referencelist.html?type=function&amp;category=raspberrypiio-camera-board&amp;s_tid=CRUX_topnav">Functions</a></li><li id="crux_nav_app" class="crux_resource"><a href="../referencelist.html?type=app&amp;category=raspberrypiio-camera-board&amp;s_tid=CRUX_topnav">Apps</a></li></ul></div></nav></div><div class="d-sm-none"><div class="container-fluid"><div class="row"><div class="col-9"><div class="mobile_crux_nav_trigger"><div class="btn-group"><button type="button" class="btn btn-default dropdown-toggle" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Resources</button><ul class="dropdown-menu"><li id="crux_nav_mobile_documentation" class="crux_resource active">Documentation</li><li id="crux_nav_mobile_example" class="crux_resource"><a href="../examples.html?category=raspberrypiio-camera-board&amp;s_tid=CRUX_topnav">Examples</a></li><li id="crux_nav_mobile_function" class="crux_resource"><a href="../referencelist.html?type=function&amp;category=raspberrypiio-camera-board&amp;s_tid=CRUX_topnav">Functions</a></li><li id="crux_nav_mobile_app" class="crux_resource"><a href="../referencelist.html?type=app&amp;category=raspberrypiio-camera-board&amp;s_tid=CRUX_topnav">Apps</a></li></ul></div></div></div><div class="col-3"><div class="translate_placeholder"></div></div></div></div></div></div></div></div></div></div></div><div class="content_container" id="content_container" itemprop="content">
<div class="container-fluid">
<div class="row">
<div class="col-12">

<main id="skip_link_anchor" tabindex="-1">
<div xmlns="http://www.w3.org/1999/xhtml" id="product_info_alert"></div><section xmlns="http://www.w3.org/1999/xhtml" id="doc_center_content" lang="en" data-language="en"><div id="pgtype-example">
<section><div class="example_icon"></div><h1 class="r2025b" itemprop="title content" id="mw_53734b75-0b00-4f75-9527-c48190aa26cd">Detect and Track Object Using Deep Learning on Raspberry Pi</h1><div class="examples_short_list hidden_ios_android" data-products="EC ME ML ML_DEEPLEARNING_LIB NN RASPPIIO RESNET18 VP"><div data-pane="metadata" class="card metadata_container"><div class="card-body metadata_content"><p class="add_margin_5">This example uses:</p><ul class="list-unstyled add_border_bottom example_product_list" itemprop="requiredprods"><li><a href="matlab:matlab.internal.addons.showAddon('EC')">Embedded Coder</a></li><li><a href="matlab:matlab.internal.addons.showAddon('ME')">MATLAB Coder</a></li><li><a href="matlab:matlab.internal.addons.showAddon('ML_DEEPLEARNING_LIB')">MATLAB Coder Interface for Deep Learning</a></li><li><a href="matlab:matlab.internal.addons.showAddon('NN')">Deep Learning Toolbox</a></li><li><a href="matlab:matlab.internal.addons.showAddon('RASPPIIO')">MATLAB Support Package for Raspberry Pi Hardware</a></li><li><a href="matlab:matlab.internal.addons.showAddon('RESNET18')">Deep Learning Toolbox Model for ResNet-18 Network</a></li><li><a href="matlab:matlab.internal.addons.showAddon('VP')">Computer Vision Toolbox</a></li></ul><div class="d-grid"><a class="btn btn_color_blue" href="matlab:openExample('raspberrypiio/DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample')" data-ex-genre="Script">Open Script</a></div></div></div></div><div itemscope="" itemtype="http://www.mathworks.com/help/schema/MathWorksDocPage/Example" itemprop="example" class="em_example"><meta itemprop="exampleid" content="raspberrypiio-DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample"><meta itemprop="exampletitle" content="Detect and Track Object Using Deep Learning on Raspberry Pi"></div><span id="DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample" class="anchor_target"></span>



<p class="shortdesc">This example shows how to use the MATLAB&#174; Support Package for Raspberry Pi&#174; Hardware to deploy a deep learning algorithm that detects and tracks an object in Connected IO and PIL modes. This algorithm uses the ResNet-18-based YOLOv2 neural network to identify the object captured by the camera mounted on a servo motor and connected to the Raspberry Pi hardware. You can experiment with different objects in your surroundings to see how accurately the network detects images on the Raspberry Pi hardware.</p>


<p>Note: You cannot generate and deploy deep learning code on Raspberry Pi hardware using macOS.</p>




<div class="procedure"><h3 class="title" id="d126e121811">Prerequisites<span id="DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample-1" class="anchor_target"></span></h3><p>Configure the Raspberry Pi network using the <strong class="emphasis bold">Hardware Setup</strong> window. During this process, download the MathWorks&#174; Raspbian image for deep learning. Instead of using the MathWorks Raspbian image, if you choose to customize an existing image on your hardware, ensure that you select the option to install the ARM&#174; Compute Library.</p><h3 class="title" id="d126e121820">Required Hardware<span id="DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample-2" class="anchor_target"></span></h3><div class="itemizedlist"><ul><li><p>Raspberry Pi hardware (Model 4 recommended)</p></li><li><p>Supported <a href="https://elinux.org/RPi_USB_Webcams" target="_blank">USB webcam</a> or <a href="https://www.raspberrypi.com/products/camera-module-v2/" target="_blank">Raspberry Pi camera module</a>
</p></li><li><p>Power adapter for the Raspberry Pi board</p></li><li><p>Servo motor</p></li><li><p>Jumper cable</p></li></ul></div><h3 class="title" id="d126e121842">Hardware Setup<span id="DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample-3" class="anchor_target"></span></h3><div class="orderedlist"><ol style="list-style: decimal;"><li><p>Power the Raspberry Pi target board.</p></li><li><p>Connect the servo motor to the Raspberry Pi target board using the jumper cables. Connect the GND and VCC pins. Additionally, in this example, you connect the servo motor signal pin to the GPIO pin 12 of the Raspberry Pi target board.</p></li><li><p>Mount the camera on top of the servo motor using sticky tape or an adhesive. This example uses a USB web camera.</p></li></ol></div><h3 class="title" id="d126e121853">Create Tracker Object<span id="DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample-4" class="anchor_target"></span></h3><p>Create the <code class="literal">tracker</code> object and obtain the ground truth data.</p><div class="code_responsive"><pre id="d126e121861" class="programlisting">tracker = raspiObjectTracker
</pre></div><div class="code_responsive"><pre id="d126e121863" class="programlisting">tracker =
</pre></div><div class="code_responsive"><pre class="programlisting">raspiObjectTracker with properties:</pre></div><div class="code_responsive"><pre class="programlisting">    BoardDetails: [1x1 struct]
           Setup: [1x1 struct]
        Detector: [1x1 struct]
  TestAndProfile: [1x1 struct]</pre></div><p>View the Raspberry Pi target board details.</p><div class="code_responsive"><pre id="d126e121868" class="programlisting">tracker.BoardDetails
</pre></div><div class="code_responsive"><pre id="d126e121870" class="programlisting">ans =
</pre></div><div class="code_responsive"><pre class="programlisting">struct with fields:</pre></div><div class="code_responsive"><pre class="programlisting">           Name: 'Raspberry Pi'
  DeviceAddress: '192.168.0.100'
       UserName: 'pi'
       Password: 'raspberry'</pre></div><p>This structure shows the name, device address, user name, and password of the Raspberry Pi board.</p><p>Note: You can change the values by using dot notation. For example, change the password to <code class="literal">MATLAB</code> using <code class="literal">tracker.BoardDetails.Password = 'MATLAB'</code>.</p><p>Check your change by viewing the properties again.</p><div class="code_responsive"><pre id="d126e121883" class="programlisting">tracker.BoardDetails
</pre></div><div class="code_responsive"><pre id="d126e121885" class="programlisting">ans =
</pre></div><div class="code_responsive"><pre class="programlisting">struct with fields:</pre></div><div class="code_responsive"><pre class="programlisting">           Name: 'Raspberry Pi'
  DeviceAddress: '192.168.0.100'
       UserName: 'pi'
       Password: 'MATLAB'</pre></div><p>The structure shows the updated password.</p><p>View the image capture setup properties.</p><div class="code_responsive"><pre id="d126e121891" class="programlisting">tracker.Setup
</pre></div><div class="code_responsive"><pre id="d126e121893" class="programlisting">ans =
</pre></div><div class="code_responsive"><pre class="programlisting">struct with fields:</pre></div><div class="code_responsive"><pre class="programlisting">  DataCaptureTime: 120
  CameraInterface: 'webcam'</pre></div><p>This structure shows the type of interface and the capture time.</p><div class="itemizedlist"><ul><li><p>
<code class="literal">DataCaptureTime</code> &#8212; Time duration in seconds for image capture of the tracked object. The default time is <code class="literal">120</code> seconds. You can change the values by using dot notation.</p></li></ul></div><p>Note: You can increase the capture time to improve the training efficiency of the neural network when detecting and tracking an object. For example, to change the capture time to <code class="literal">300</code> seconds use <code class="literal">tracker.Setup.DataCaptureTime = 300</code>.</p><div class="itemizedlist"><ul><li><p>
<code class="literal">CameraInterface</code> &#8212; Type of camera interface used to detect and track the object, which can be a <a href="webcam.html" data-docid="mlsupportpkg#buerllq-1" class="a"><code class="olink">webcam</code></a> or <a href="cameraboard.html" data-docid="mlsupportpkg#buno94s" class="a"><code class="olink">cameraboard</code></a> object. The default interface is <code class="literal">webcam</code>.</p></li></ul></div><p>Place the object to detect and track in front of the camera and run this command at the MATLAB Command Window:</p><div class="code_responsive"><pre id="d126e121926" class="programlisting">objectTrackingSetup(tracker)
</pre></div><p>This command establishes an IO connection with the Raspberry Pi hardware and obtains the ground truth data from the webcam. It also opens the <strong class="emphasis bold">Video Labeler</strong> app.</p><p>The camera captures images for the time that you specify in the <code class="literal">DataCaptureTime</code> property. The app saves the images to a folder in the current working directory named <code class="literal">Data</code>-_date_-_timestamp_, where <code class="literal">date</code> is the current date and <code class="literal">timestamp</code> is the current time.</p><p>Copy one sample image from the <code class="literal">Data</code>-_date_-_timestamp_ folder and paste it in the current working directory. Note the file name so that you can use it as a reference image while training the network by setting the <code class="literal">tracker.Detector.SampleImage</code> property.</p><p>
</p>
<div class="informalfigure"><div id="d126e121953" class="mediaobject"><p><img src="../../examples/raspberrypiio/win64/xxobjectTrackingSetup.png"></p></div></div><p>
 </p><p>Running the <code class="literal">objectTrackingSetup(tracker)</code> command also opens the <a href="../../vision/ref/videolabeler-app.html" data-docid="vision_ref#mw_f2d359b5-81b9-4fda-9c7e-84a6164506b8" class="a">Video Labeler</a><span role="cross_prod"> (Computer Vision Toolbox)</span> app. This app allows you to mark the region of interest (ROI), automatically label across image frames using an automation algorithm, and export the labeled ground truth.</p><p>
</p>
<div class="informalfigure"><div id="d126e121966" class="mediaobject"><p><img src="../../examples/raspberrypiio/win64/xxvideo_Labeler_app.PNG"></p></div></div><p>
 </p><p>Follow these steps in the Video Labeler app:</p><div class="orderedlist"><ol style="list-style: decimal;"><li><p>In the <strong class="emphasis bold">ROI Labels</strong> pane, click <strong class="emphasis bold">Label</strong>. Create a <strong class="emphasis bold">Rectangular</strong> label, name it, and click <strong class="emphasis bold">OK</strong>. In this example, the object has the name <code class="literal">ball</code>.</p></li><li><p>Use the mouse to draw a rectangular ROI in the image.</p></li><li><p>In the <strong class="emphasis bold">Automate Labeling</strong> section, use the <strong class="emphasis bold">Select Algorithm</strong> button to select the <code class="literal">Point Tracker</code> algorithm and then click <strong class="emphasis bold">Automate</strong>. The algorithm instructions appear in the right pane, and the selected labels are available to automate.</p></li><li><p>In the <strong class="emphasis bold">Run</strong> section, click <strong class="emphasis bold">Run</strong> to automate labeling for the image sequence.</p></li><li><p>When you are satisfied with the algorithm results, in the <strong class="emphasis bold">Close</strong> section, click <strong class="emphasis bold">Accept</strong>.</p></li><li><p>Under <strong class="emphasis bold">Export Labels</strong>, select <strong class="emphasis bold">To File</strong> to export the labeled data to a MAT file <strong class="emphasis bold">objectLabel.mat</strong>.</p></li></ol></div><p>For detailed information on how to use the Video Labeler app, see <a href="../../vision/ref/videolabeler-app.html" data-docid="vision_ref#mw_f2d359b5-81b9-4fda-9c7e-84a6164506b8" class="a">Video Labeler</a><span role="cross_prod"> (Computer Vision Toolbox)</span> and <a href="../../vision/ug/get-started-with-the-video-labeler.html" data-docid="vision_ug#mw_552539ba-92c5-49d5-adbb-3e21ab32460a" class="a">Get Started with the Video Labeler</a><span role="cross_prod"> (Computer Vision Toolbox)</span>.</p><h3 class="title" id="d126e122041">Detect Object<span id="DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample-26" class="anchor_target"></span></h3><p>Train the YOLOv2 object detector from the captured ground truth data and verify the detected object in Connected IO and PIL modes.</p><p>Use the <code class="literal">tracker.Detector</code> command to check if the value of the <code class="literal">LabeledData</code> field is the name of the MAT file that you exported using the Video Labeler app.</p><div class="code_responsive"><pre id="d126e122052" class="programlisting">tracker.Detector
</pre></div><div class="code_responsive"><pre id="d126e122054" class="programlisting">ans =
</pre></div><div class="code_responsive"><pre class="programlisting">struct with fields:</pre></div><div class="code_responsive"><pre class="programlisting">      LabeledData: 'objectLabel.mat'
        ImageSize: [224 224 3]
       NumClasses: 1
      SampleImage: 'sampleImage.jpg'
          Network: [1x1 struct]
  TrainingOptions: [1x1 struct]
  DetectorMatFile: 'detectorSaved.mat'</pre></div><h3 class="title" id="d126e122058">Train YOLOv2 Object Detector<span id="DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample-30" class="anchor_target"></span></h3><p>Train the YOLOv2 object detector with the images captured from the camera. The <code class="literal">objectLabel.mat</code> file contains the exported ground truth data. Use this file to train the YOLOv2 object detector.</p><p>From the current directory of the captured object images, select a valid sample image as a reference for training the neural network. For this example, set the sample image to <code class="literal">image_50.png</code>.</p><div class="code_responsive"><pre id="d126e122070" class="programlisting">tracker.Detector.SampleImage = <span style="color:#A020F0">'image_50.png'</span>;
</pre></div><p>Train the YOLOv2 object detector and save it as the MAT file <code class="literal">detectorSaved.mat</code>.</p><div class="code_responsive"><pre id="d126e122076" class="programlisting">createObjectDetector(tracker)
</pre></div><p>
</p>
<div class="informalfigure"><div id="d126e122081" class="mediaobject"><p><img src="../../examples/raspberrypiio/win64/xxcreateObjectDetector.PNG"></p></div></div><p>
 </p><p>A figure window containing the selected sample image opens once the YOLOv2 neural network has finished training the images. This image shows an ROI and the probability of match within the training network.</p><p>
</p>
<div class="informalfigure"><div id="d126e122089" class="mediaobject"><p><img src="../../examples/raspberrypiio/win64/xxdetection_connectedIO_mode.PNG"></p></div></div><p>
 </p><p>
<strong class="emphasis bold">Note</strong>: You can verify the object detection in either Connected IO or PIL modes.</p><h3 class="title" id="d126e122098">Verify Object Detection in Connected IO Mode<span id="DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample-37" class="anchor_target"></span></h3><p>Use the Connected IO mode to verify the detected object. The image capture process takes place on Raspberry Pi hardware itself.</p><p>Run this command at the MATLAB Command Window:</p><div class="code_responsive"><pre id="d126e122104" class="programlisting">tracker.TestAndProfile
</pre></div><div class="code_responsive"><pre id="d126e122106" class="programlisting">ans =
</pre></div><div class="code_responsive"><pre class="programlisting">struct with fields:</pre></div><div class="code_responsive"><pre class="programlisting">  PredictFunction: 'raspi_yolov2_detect'
         TestMode: 'IO'
     TestDuration:  60
            Servo: [1x1 struct]</pre></div><p>The default <code class="literal">TestMode</code> value is <code class="literal">'IO'</code>.</p><p>Verify object detection in the IO mode:</p><div class="code_responsive"><pre id="d126e122117" class="programlisting">startTestAndProfile(tracker)
</pre></div><p>A camera window opens showing an ROI and the probability of match within the training network for the detected object.</p><p>
</p>
<div class="informalfigure"><div id="d126e122124" class="mediaobject"><p><img src="../../examples/raspberrypiio/win64/xxfigure_window.PNG"></p></div></div><p>
 </p><h3 class="title" id="d126e122128">Verify Object Detection in PIL Mode<span id="DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample-45" class="anchor_target"></span></h3><p>Use the PIL mode to verify the detected object. The image capture process takes place on the Raspberry Pi hardware itself. The <code class="literal">raspi_yolov2_detect</code> function runs on the Raspberry Pi board in the PIL mode.</p><p>Note: Object detection and tracking in the PIL mode takes some time to execute.</p><p>Change the object detection mode to <code class="literal">'PIL'</code>.</p><div class="code_responsive"><pre id="d126e122141" class="programlisting">tracker.TestAndProfile.TestMode = <span style="color:#A020F0">'PIL'</span>;
</pre></div><p>Run this command at the MATLAB Command prompt to verify the object detection in PIL mode.</p><div class="code_responsive"><pre id="d126e122144" class="programlisting">startTestAndProfile(tracker)
</pre></div><p>A camera window opens showing an ROI and the probability of match within the training network for the detected object.</p><p>
</p>
<div class="informalfigure"><div id="d126e122150" class="mediaobject"><p><img src="../../examples/raspberrypiio/win64/xxdetection_PIL_mode.PNG"></p></div></div><p>
 </p><p>
</p>
<div class="informalfigure"><div id="d126e122157" class="mediaobject"><p><img src="../../examples/raspberrypiio/win64/xxdetection_PIL_message.PNG"></p></div></div><p>
 </p><p>To view the <strong class="emphasis bold">Code Execution Profiling Report</strong>, click the <strong class="emphasis bold">Execution profiling report</strong> link.</p><p>
</p>
<div class="informalfigure"><div id="d126e122173" class="mediaobject"><p><img src="../../examples/raspberrypiio/win64/xxcode_execution_profiling_report.PNG"></p></div></div><p>
 </p><h3 class="title" id="d126e122177">Configure Servo Motor Parameters<span id="DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample-52" class="anchor_target"></span></h3><p>To track an object after its successful detection, you must configure the servo motor parameters.</p><p>View the servo motor parameters.</p><div class="code_responsive"><pre id="d126e122183" class="programlisting">tracker.TestAndProfile.Servo
</pre></div><div class="code_responsive"><pre id="d126e122185" class="programlisting">ans =
</pre></div><div class="code_responsive"><pre class="programlisting">struct with fields:</pre></div><div class="code_responsive"><pre class="programlisting">     TestWithServo: 0
         Increment: 0.5000
         PinNumber: 12
     StartPosition: 90
  MinPulseDuration: 5.0000e-04
  MaxPulseDuration: 0.0025</pre></div><div class="itemizedlist"><ul><li><p>
<code class="literal">TestWithServo</code> - Flag to enable or disable the servo motor for tracking the object. The default value of this field is <code class="literal">false</code>. Enable the servo motor using this command:</p></li></ul></div><div class="code_responsive"><pre id="d126e122197" class="programlisting">tracker.TestAndProfile.Servo.TestWithServo = true;
</pre></div><p>You can modify these parameters based on the datasheet for your servo motor:</p><p>1. <code class="literal">Increment</code> - Step angle size of rotation of the servo motor. The default step angle value is <code class="literal">0.5</code> degrees.</p><p>2. <code class="literal">PinNumber</code> - GPIO pin number of the Raspberry Pi target board to which the servo motor is connected.</p><p>3. <code class="literal">StartPosition</code> - Starting angle position of the servo motor. The servo motor rotates from 0 to 180 degrees. The default starting angle is 90 degrees.</p><p>4. <code class="literal">MinPulseDuration</code> - Minimum pulse duration to move to 0 degrees.</p><p>5. <code class="literal">MaxPulseDuration</code> - Maximum pulse duration to move to 180 degrees.</p><h3 class="title" id="d126e122223">Track Object in Connected IO Mode<span id="DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample-63" class="anchor_target"></span></h3><p>Use these commands to ensure that object tracking on the servo motor is enabled and the test mode is set to IO:</p><div class="code_responsive"><pre id="d126e122228" class="programlisting">tracker.TestAndProfile.Servo.TestWithServo = true;
</pre></div><div class="code_responsive"><pre id="d126e122230" class="programlisting">tracker.TestAndProfile.TestMode = <span style="color:#A020F0">'IO'</span>;
</pre></div><p>Track the detected object in connected IO mode:</p><div class="code_responsive"><pre id="d126e122233" class="programlisting">startTestAndProfile(tracker)
</pre></div><p>Place the object in front of the camera and move the object. Observe that the servo motor rotates to follow the moving object.</p><p>A camera window opens with the ROI and the probability of match with the training network. A separate window opens to display the angle of the servo motor.</p><p>
</p>
<div class="informalfigure"><div id="d126e122240" class="mediaobject"><p><img src="../../examples/raspberrypiio/win64/xxtracking_connectedIO_mode.PNG"></p></div></div><p>
 </p><p>
</p>
<div class="informalfigure"><div id="d126e122247" class="mediaobject"><p><img src="../../examples/raspberrypiio/win64/xxtracking_connectedIO_message.PNG"></p></div></div><p>
 </p><h3 class="title" id="d126e122251">Track Object in PIL Mode<span id="DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample-70" class="anchor_target"></span></h3><p>Use these commands to ensure that object tracking on the servo motor is enabled and the test mode is set to PIL:</p><div class="code_responsive"><pre id="d126e122256" class="programlisting">tracker.TestAndProfile.Servo.TestWithServo = true
</pre></div><div class="code_responsive"><pre id="d126e122258" class="programlisting">tracker.TestAndProfile.TestMode = <span style="color:#A020F0">'PIL'</span>;
</pre></div><p>Track the detected object in connected PIL mode:</p><div class="code_responsive"><pre id="d126e122261" class="programlisting">startTestAndProfile(tracker)
</pre></div><p>Place the object in front of the camera and move the object. Observe that the servo motor rotates to follow the moving object.</p><p>A camera window opens with the ROI and the probability of match with the training network. A separate window opens to display the angle of the servo motor.</p><p>
</p>
<div class="informalfigure"><div id="d126e122268" class="mediaobject"><p><img src="../../examples/raspberrypiio/win64/xxtracking_PIL_mode.PNG"></p></div></div><p>
 </p><p>
</p>
<div class="informalfigure"><div id="d126e122275" class="mediaobject"><p><img src="../../examples/raspberrypiio/win64/xxtracking_PIL_message.PNG"></p></div></div><p>
 </p><h3 class="title" id="d126e122280">Deploy on Raspberry Pi Target Board<span id="DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample-77" class="anchor_target"></span></h3><p>The <code class="literal">raspi_object_tracking</code> function executes the object tracking algorithm on the Raspberry Pi hardware board. This function follows the tracking algorithm specified in the <code class="literal">raspi_yolov2_detect</code> function.</p><p>Before deploying the code on the Raspberry Pi target board, open the <code class="literal">raspi_object_tracking.m</code> function file and configure the parameters by modifying one or more of these:</p><div class="itemizedlist"><ul><li><p>Input image size for the ResNet-18 neural network</p></li><li><p>Observations regarding the servo motor incremental angle, starting position, and so on</p></li><li><p>Type of camera interface for capturing images of the object</p></li></ul></div><p>The <code class="literal">raspi_yolov2_detect</code> function uses the YOLOv2-based deconvolutional neural network (DNN) saved as a MAT file. Pass <code class="literal">inputImg</code> as an input to the detected network. If the object is detected, <code class="literal">outImg</code> contains the bounding box information of the detected object. <code class="literal">posIncFactor</code> indicates the rotation factor required to maintain the object at the center of the frame for this bounding box.</p><p>Open the <code class="literal">raspi_yolov2_detect.m</code> file and enter the name of the saved trained neural network MAT file <code class="literal">detectorSaved.mat</code> in the <code class="literal">yolov2obj</code> parameter.</p><p>Run these commands at the MATLAB command prompt. Note: For Raspberry Pi with 32-bit OS use <code class="literal">targetHardware('Raspberry Pi')</code> and for 64-bit OS use <code class="literal">targetHardware('Raspberry Pi (64bit)')</code>.</p><div class="code_responsive"><pre id="d126e122325" class="programlisting">t = targetHardware(<span style="color:#A020F0">'Raspberry Pi (64bit)'</span>)
</pre></div><div class="code_responsive"><pre id="d126e122327" class="programlisting">t.CoderConfig.TargetLang = <span style="color:#A020F0">'C++'</span>;
</pre></div><div class="code_responsive"><pre id="d126e122329" class="programlisting">dlcfg = coder.DeepLearningConfig(<span style="color:#A020F0">'arm-compute'</span>);
</pre></div><div class="code_responsive"><pre id="d126e122331" class="programlisting">dlcfg.ArmArchitecture = <span style="color:#A020F0">'armv7'</span>;
</pre></div><div class="code_responsive"><pre id="d126e122334" class="programlisting">t.CoderConfig.DeepLearningConfig = dlcfg;
</pre></div><div class="code_responsive"><pre id="d126e122336" class="programlisting">deploy(t,<span style="color:#A020F0">'raspi_object_tracking'</span>)
</pre></div><p>Observe that the camera mounted on the servo motor detects the object and also tracks its movement. On the Raspberry Pi desktop, open the camera display to observe the live tracking results.</p><p>
</p>
<div class="informalfigure"><div id="d126e122342" class="mediaobject"><p><img src="../../examples/raspberrypiio/win64/xxdeploy_raspberrypi_hardware.PNG"></p></div></div><p>
 </p><p>The deployed function initiates code generation of the <code class="literal">raspi_object_tracking</code> function. Once code generation is complete, MATLAB generates a code generation report. Use this report to debug the <code class="literal">raspi_object_tracking</code> function for any build errors or warnings in the generated code.</p><p>After successfully generating the code, the support package loads and runs the object classification algorithm as a standalone executable on the hardware. The executable starts detecting the objects in the acquired video and displays the predicted labels and their associated probabilities. To view the Raspberry Pi screen, use a VNC viewer and open a remote session on the hardware to get the display. You can alternatively connect an HDMI cable from the monitor to the hardware.</p><h3 class="title" id="d126e122353">Other Things to Try<span id="DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample-91" class="anchor_target"></span></h3><div class="itemizedlist"><ul><li><p>Train the YOLOv2 object detector to detect and track more than one object.</p></li><li><p>Use a neural network other than ResNet-18 for training the objects and observe the differences in the obtained results.</p></li><li><p>Use a different algorithm in the <a href="../../vision/ref/videolabeler-app.html" data-docid="vision_ref#mw_f2d359b5-81b9-4fda-9c7e-84a6164506b8" class="a">Video Labeler</a><span role="cross_prod"> (Computer Vision Toolbox)</span> app and compare the results with the <code class="literal">Point Tracker</code> algorithm.</p></li><li><p>Change the input image size provided in the <code class="literal">raspi_yolov2_detect</code> function and observe the object detection image.</p></li></ul></div><h3 class="title" id="d126e122374">See Also<span id="DetectAndTrackObjectUsingDeepLearningOnRaspberryPiExample-92" class="anchor_target"></span></h3><div class="itemizedlist"><ul><li><p>
<a href="identify-objects-within-video-using-resNet-50-on-raspberry-pi-hardware.html" data-docid="mlsupportpkg#example-resnet50_webcam" class="a">Identify Objects Within Live Video Using ResNet-50 on Raspberry Pi Hardware</a>
</p></li><li><p>
<a href="raspberrypiio.html" data-docid="mlsupportpkg#bu6ial4" class="a"><code class="olink">webcam</code></a>
</p></li><li><p>
<a href="cameraboard.html" data-docid="mlsupportpkg#buno94s" class="a"><code class="olink">cameraboard</code></a>
</p></li><li><p>
<a href="../../vision/ref/videolabeler-app.html" data-docid="vision_ref#mw_f2d359b5-81b9-4fda-9c7e-84a6164506b8" class="a">Video Labeler</a><span role="cross_prod"> (Computer Vision Toolbox)</span> app</p></li><li><p>
<a href="../../vision/ug/get-started-with-the-video-labeler.html" data-docid="vision_ug#mw_552539ba-92c5-49d5-adbb-3e21ab32460a" class="a">Get Started with the Video Labeler</a><span role="cross_prod"> (Computer Vision Toolbox)</span>
</p></li></ul></div></div></section>
    </div></section><div xmlns="http://www.w3.org/1999/xhtml" class="clearfix"></div>
<div xmlns="http://www.w3.org/1999/xhtml" align="center" class="feedbackblock" id="mw_docsurvey"><script src="https://www.mathworks.com/help/docsurvey/docfeedback.js"></script>
<script>loadSurveyHidden();</script>
<link rel="stylesheet" href="https://www.mathworks.com/help/docsurvey/release/index-css.css" type="text/css">
<script src="https://www.mathworks.com/help/docsurvey/release/bundle.index.js"></script>

<script>initDocSurvey();</script></div></main>


</div>
</div>
</div>
</div><!--close_0960-->
<footer xmlns="http://www.w3.org/1999/xhtml" id="footer" class="bs-footer">
<div class="container-fluid">
<div class="footer">
<div class="row">
<div class="col-12">
<p class="copyright"> 1994-2025 The MathWorks, Inc.</p>
<ul class="footernav"><li class="footernav_help"><a href="matlab:web(matlab.internal.licenseAgreement)">Terms of Use</a></li><li class="footernav_patents"><a href="matlab:web([matlabroot '/patents.txt'])">Patents</a></li><li class="footernav_trademarks"><a href="matlab:web([matlabroot '/trademarks.txt'])">Trademarks</a></li><li class="footernav_piracy"><a href="matlab:web([docroot '/acknowledgments.html'])">Acknowledgments</a></li></ul></div>
</div>
</div>
</div>
</footer>
</div><!--close row-offcanvas-->
</div><!--close_0970-->
</body>
</html>
